# Self-Dispatching Import Jobs - Rekursive Batch-Verarbeitung

## Ãœbersicht

Die **ImportMissingDataJobs** verwenden ein **selbst-dispatchendes** System fÃ¼r die Batch-Verarbeitung. Das bedeutet:

1. Du startest den Job **einmal**
2. Der Job verarbeitet einen **Batch** (z.B. 100 Episoden)
3. Wenn noch EintrÃ¤ge Ã¼brig sind, **dispatched er sich selbst** erneut
4. Dies wiederholt sich automatisch, bis **alle** EintrÃ¤ge importiert sind

## Wie es funktioniert

```
Start: ImportMissingEpisodesDataJob::dispatch(100, 10)
  â†“
Batch 1: Verarbeite 100 Episoden (400 verbleiben)
  â†“ (10 Sekunden VerzÃ¶gerung)
Batch 2: Verarbeite 100 Episoden (300 verbleiben)  â† automatisch dispatched
  â†“ (10 Sekunden VerzÃ¶gerung)
Batch 3: Verarbeite 100 Episoden (200 verbleiben)  â† automatisch dispatched
  â†“ (10 Sekunden VerzÃ¶gerung)
Batch 4: Verarbeite 100 Episoden (100 verbleiben)  â† automatisch dispatched
  â†“ (10 Sekunden VerzÃ¶gerung)
Batch 5: Verarbeite 100 Episoden (0 verbleiben)    â† automatisch dispatched
  â†“
Fertig! âœ“
```

## Jobs

### ImportMissingSeriesDataJob

**Parameter:**

- `$batchSize` (int, Standard: 50): Anzahl Serien pro Batch
- `$delaySeconds` (int, Standard: 10): VerzÃ¶gerung in Sekunden zwischen Batches

**Automatisches Verhalten:**

- PrÃ¼ft, wie viele Serien ohne Daten existieren
- Verarbeitet einen Batch
- Wenn noch Serien Ã¼brig: dispatched sich selbst mit `delay()`
- Wenn keine mehr Ã¼brig: beendet sich

### ImportMissingEpisodesDataJob

**Parameter:**

- `$batchSize` (int, Standard: 100): Anzahl Episoden pro Batch
- `$delaySeconds` (int, Standard: 10): VerzÃ¶gerung in Sekunden zwischen Batches

**Automatisches Verhalten:**

- PrÃ¼ft, wie viele Episoden ohne Daten existieren
- Verarbeitet einen Batch
- Wenn noch Episoden Ã¼brig: dispatched sich selbst mit `delay()`
- Wenn keine mehr Ã¼brig: beendet sich

## Verwendung

### Artisan Commands

#### Episoden (Standard: 100 pro Batch, 10s VerzÃ¶gerung)

```bash
# Mit Standardwerten
php artisan episodes:import-missing-data

# Eigene Batch-GrÃ¶ÃŸe
php artisan episodes:import-missing-data --batch-size=200

# Eigene VerzÃ¶gerung
php artisan episodes:import-missing-data --delay=5

# Beides anpassen
php artisan episodes:import-missing-data --batch-size=50 --delay=20
```

#### Serien (Standard: 50 pro Batch, 10s VerzÃ¶gerung)

```bash
# Mit Standardwerten
php artisan series:import-missing-data

# Eigene Batch-GrÃ¶ÃŸe
php artisan series:import-missing-data --batch-size=100

# Eigene VerzÃ¶gerung
php artisan series:import-missing-data --delay=15

# Beides anpassen
php artisan series:import-missing-data --batch-size=25 --delay=30
```

### Programmatisch

```php
use App\Jobs\ImportMissingEpisodesDataMissingDataJob;
use App\Jobs\ImportMissingSeriesDataMissingDataJob;

// Episoden: 100 pro Batch, 10s VerzÃ¶gerung
ImportMissingEpisodesDataMissingDataJob::dispatch(100, 10);

// Episoden: 200 pro Batch, 5s VerzÃ¶gerung
ImportMissingEpisodesDataMissingDataJob::dispatch(200, 5);

// Serien: 50 pro Batch, 10s VerzÃ¶gerung
ImportMissingSeriesDataMissingDataJob::dispatch(50, 10);

// Serien: 25 pro Batch, 30s VerzÃ¶gerung
ImportMissingSeriesDataMissingDataJob::dispatch(25, 30);
```

## Vorteile des selbst-dispatchenden Systems

### 1. Einfache Verwendung

```bash
# Nur einmal starten - der Rest lÃ¤uft automatisch
php artisan episodes:import-missing-data
```

Statt:

```bash
# Mehrfach manuell ausfÃ¼hren (altes System)
php artisan episodes:import-missing-data
php artisan episodes:import-missing-data
php artisan episodes:import-missing-data
# ...
```

### 2. Automatische VollstÃ¤ndigkeit

- Der Job lÃ¤uft **garantiert**, bis alle EintrÃ¤ge importiert sind
- Keine manuellen Wiederholungen nÃ¶tig
- Keine vergessenen EintrÃ¤ge

### 3. API-Rate-Limit-Schutz

- VerzÃ¶gerung zwischen Batches (`$delaySeconds`)
- Verhindert Ãœberlastung der externen API
- Anpassbar je nach API-Limits

### 4. Queue-freundlich

- Jobs werden mit `delay()` geplant
- Andere Jobs kÃ¶nnen zwischendurch laufen
- Keine Blockierung der Queue

### 5. Monitoring & Logging

- Jeder Batch wird einzeln geloggt
- Klare Fortschrittsanzeige
- Verbleibende Anzahl wird angezeigt

## Logging

Jeder Batch loggt seinen Fortschritt:

### Batch-Start

```json
{
    "message": "PrÃ¼fe Episoden ohne importierte Daten",
    "context": {
        "batch_size": 100,
        "delay_seconds": 10
    }
}
```

### Batch-Info

```
"Gefunden: 534 Episoden ohne importierte Daten, verarbeite 100 in diesem Batch"
```

### Batch-Erfolg (mit Fortsetzung)

```json
{
    "message": "EpisodeDataJob fÃ¼r 100 von 100 Episoden dispatched (434 verbleiben) - dispatche nÃ¤chsten Batch",
    "context": {
        "dispatched": 100,
        "processed": 100,
        "remaining": 434,
        "continues": true
    }
}
```

### Letzter Batch (Abschluss)

```json
{
    "message": "EpisodeDataJob fÃ¼r 34 von 34 Episoden dispatched - Import vollstÃ¤ndig abgeschlossen!",
    "context": {
        "dispatched": 34,
        "processed": 34,
        "remaining": 0,
        "continues": false
    }
}
```

## Performance-Tuning

### Batch-GrÃ¶ÃŸe anpassen

**Zu klein (z.B. 10):**

- âŒ Viele Job-Dispatches
- âŒ Overhead durch viele kleine Batches
- âœ… Sehr geringe Last pro Batch

**Optimal (50-100):**

- âœ… Gutes Gleichgewicht
- âœ… Moderate Last
- âœ… Ãœberschaubare Anzahl Batches

**Zu groÃŸ (z.B. 1000):**

- âœ… Wenige Batches
- âŒ Hohe Last pro Batch
- âŒ Lange Laufzeit pro Batch
- âŒ Probleme bei Fehlern

### VerzÃ¶gerung anpassen

**Keine VerzÃ¶gerung (0s):**

- âŒ Kann API-Limits Ã¼berschreiten
- âŒ Queue-Ãœberlastung mÃ¶glich
- âœ… Schnellster Import

**Kurze VerzÃ¶gerung (5-10s):**

- âœ… API-Schutz
- âœ… Queue bleibt reaktiv
- âœ… Gute Balance

**Lange VerzÃ¶gerung (30-60s):**

- âœ… Maximaler API-Schutz
- âœ… Sehr sanft zur Infrastruktur
- âŒ Sehr langer Gesamtimport

## Empfehlungen

### Episoden

```bash
# Standard - gut fÃ¼r die meisten FÃ¤lle
php artisan episodes:import-missing-data
# â†’ 100 pro Batch, 10s VerzÃ¶gerung

# Bei vielen Episoden & strenger API
php artisan episodes:import-missing-data --batch-size=50 --delay=20

# Schneller Import (bei lockerer API)
php artisan episodes:import-missing-data --batch-size=200 --delay=5
```

### Serien

```bash
# Standard - gut fÃ¼r die meisten FÃ¤lle
php artisan series:import-missing-data
# â†’ 50 pro Batch, 10s VerzÃ¶gerung

# Bei sehr vielen Serien
php artisan series:import-missing-data --batch-size=100 --delay=5

# Vorsichtiger Import
php artisan series:import-missing-data --batch-size=25 --delay=30
```

## Scheduler-Integration

Da sich die Jobs selbst dispatchen, brauchst du sie nur **einmal** zu starten:

```php
use Illuminate\Support\Facades\Schedule;

// Einmal tÃ¤glich prÃ¼fen, ob neue EintrÃ¤ge da sind
// Der Job lÃ¤uft dann automatisch bis alle importiert sind
Schedule::command('series:import-missing-data')
    ->daily()
    ->withoutOverlapping();

Schedule::command('episodes:import-missing-data')
    ->daily()
    ->withoutOverlapping();
```

**Wichtig:** `withoutOverlapping()` verhindert, dass ein neuer Durchlauf startet, wÃ¤hrend noch einer lÃ¤uft.

## Monitoring

### Queue beobachten

```bash
# Queue-Worker mit Output
php artisan queue:work --verbose

# Einzelnen Job ausfÃ¼hren (zum Testen)
php artisan queue:work --once
```

### Logs prÃ¼fen

```bash
# Laravel-Logs
tail -f storage/logs/laravel.log

# Job-Logs in Datenbank
SELECT * FROM job_logs 
WHERE job_class = 'App\\Jobs\\ImportMissingEpisodesDataJob' 
ORDER BY created_at DESC;
```

### Fortschritt verfolgen

```bash
# Verbleibende Episoden ohne Daten
SELECT COUNT(*) FROM episodes WHERE data_last_updated_at IS NULL;

# Verbleibende Serien ohne Daten
SELECT COUNT(*) FROM series WHERE data_last_updated_at IS NULL;
```

## Fehlerbehandlung

### Was passiert bei Fehlern?

**Einzelner EpisodeDataJob schlÃ¤gt fehl:**

- âŒ Diese Episode wird nicht importiert
- âœ… Andere Episoden im Batch werden weiter verarbeitet
- âœ… Job lÃ¤uft normal weiter
- ğŸ“ Fehler wird geloggt

**Ganzer Batch schlÃ¤gt fehl:**

- âŒ Dieser Batch wird nicht verarbeitet
- âœ… Laravel Queue Retry-Mechanismus greift
- âœ… Job wird erneut versucht (falls konfiguriert)

### Best Practice

```php
// In .env oder Queue-Konfiguration
QUEUE_RETRY_AFTER=600  // 10 Minuten
```

```bash
# Queue-Worker mit Retries
php artisan queue:work --tries=3 --timeout=300
```

## Abbruch & Neustart

### Job manuell stoppen

```bash
# Queue-Worker stoppen
# Laufende Jobs werden beendet
pkill -f "queue:work"
```

### Neustart

```bash
# Einfach erneut starten - er beginnt von vorn
php artisan episodes:import-missing-data

# PrÃ¼ft automatisch, wie viele noch fehlen
# Und verarbeitet nur die verbleibenden
```

## Unterschied zu vorherigen Versionen

### Alt: Manuelles Limit-System

```bash
# Musste mehrfach manuell ausgefÃ¼hrt werden
php artisan episodes:import-missing-data --limit=100
# â†’ 100 verarbeitet, 400 Ã¼brig

php artisan episodes:import-missing-data --limit=100
# â†’ 100 verarbeitet, 300 Ã¼brig

# ... usw. (manuell wiederholen)
```

### Neu: Selbst-dispatchendes System

```bash
# Nur einmal starten
php artisan episodes:import-missing-data
# â†’ Job lÃ¤uft automatisch bis alle fertig sind
```

## Zusammenfassung

âœ… **Einmal starten** - automatische VervollstÃ¤ndigung
âœ… **API-Schutz** durch konfigurierbare VerzÃ¶gerung
âœ… **Monitoring** durch detailliertes Logging
âœ… **Flexibel** - Batch-GrÃ¶ÃŸe und VerzÃ¶gerung anpassbar
âœ… **Queue-freundlich** - mit `delay()` geplant
âœ… **Fehlertoleranz** - einzelne Fehler stoppen nicht den Gesamtprozess

**Perfekt fÃ¼r groÃŸe Datenmengen!** ğŸš€

